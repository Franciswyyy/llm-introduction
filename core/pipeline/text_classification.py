#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Text Classification Pipeline - æ–‡æœ¬åˆ†ç±»æµæ°´çº¿
ç»„åˆæ•°æ®åŠ è½½ã€åµŒå…¥ç”Ÿæˆã€åˆ†ç±»å™¨è®­ç»ƒå’Œè¯„ä¼°çš„å®Œæ•´æµç¨‹
"""

from typing import Dict, List, Any, Optional, Tuple
import numpy as np
from pathlib import Path
import yaml
import json
from datetime import datetime

from ..data.base import BaseDataLoader
from ..embeddings.base import BaseEmbedding
from ..classifiers.base import BaseClassifier
from ..evaluation.metrics import BaseEvaluator


class TextClassificationPipeline:
    """æ–‡æœ¬åˆ†ç±»æµæ°´çº¿"""
    
    def __init__(self, 
                 data_loader: BaseDataLoader,
                 embedding_model: BaseEmbedding,
                 classifier: BaseClassifier,
                 evaluator: BaseEvaluator,
                 config: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–æµæ°´çº¿
        
        Args:
            data_loader: æ•°æ®åŠ è½½å™¨
            embedding_model: åµŒå…¥æ¨¡å‹
            classifier: åˆ†ç±»å™¨
            evaluator: è¯„ä¼°å™¨
            config: æµæ°´çº¿é…ç½®
        """
        self.data_loader = data_loader
        self.embedding_model = embedding_model
        self.classifier = classifier
        self.evaluator = evaluator
        self.config = config or {}
        
        # æµæ°´çº¿çŠ¶æ€
        self.is_data_loaded = False
        self.is_embeddings_generated = False
        self.is_model_trained = False
        
        # ç¼“å­˜æ•°æ®
        self.train_embeddings = None
        self.test_embeddings = None
        self.train_labels = None
        self.test_labels = None
        self.class_names = None
        
        # ç»“æœå­˜å‚¨
        self.results = {}
        self.predictions = {}
    
    @classmethod
    def from_config(cls, config_path: str) -> 'TextClassificationPipeline':
        """
        ä»é…ç½®æ–‡ä»¶åˆ›å»ºæµæ°´çº¿
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            
        Returns:
            æµæ°´çº¿å®ä¾‹
        """
        with open(config_path, 'r', encoding='utf-8') as f:
            if config_path.endswith('.yaml') or config_path.endswith('.yml'):
                config = yaml.safe_load(f)
            else:
                config = json.load(f)
        
        # è¿™é‡Œéœ€è¦æ ¹æ®é…ç½®åˆ›å»ºå„ä¸ªç»„ä»¶
        # å®é™…å®ç°éœ€è¦å·¥å‚æ–¹æ³•
        raise NotImplementedError("éœ€è¦å®ç°ç»„ä»¶å·¥å‚æ–¹æ³•")
    
    def load_data(self) -> Dict[str, Any]:
        """
        åŠ è½½æ•°æ®
        
        Returns:
            æ•°æ®åŠ è½½ç»“æœ
        """
        print("ğŸ”„ æ­£åœ¨åŠ è½½æ•°æ®...")
        
        # åŠ è½½æ•°æ®
        data = self.data_loader.load()
        
        # éªŒè¯æ•°æ®
        if not self.data_loader.validate_data():
            raise ValueError("æ•°æ®éªŒè¯å¤±è´¥")
        
        # è·å–ç±»åˆ«åç§°
        self.class_names = self.data_loader.get_label_names()
        
        self.is_data_loaded = True
        
        # è·å–æ•°æ®é›†ä¿¡æ¯
        data_info = self.data_loader.get_dataset_info()
        print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {data_info}")
        
        return data_info
    
    def generate_embeddings(self, cache_embeddings: bool = True) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ–‡æœ¬åµŒå…¥
        
        Args:
            cache_embeddings: æ˜¯å¦ç¼“å­˜åµŒå…¥å‘é‡
            
        Returns:
            åµŒå…¥ç”Ÿæˆç»“æœ
        """
        if not self.is_data_loaded:
            self.load_data()
        
        print("ğŸ”„ æ­£åœ¨ç”Ÿæˆæ–‡æœ¬åµŒå…¥...")
        
        # åŠ è½½åµŒå…¥æ¨¡å‹
        if not self.embedding_model._is_loaded:
            self.embedding_model.load_model()
        
        # ç”Ÿæˆè®­ç»ƒé›†åµŒå…¥
        train_texts = self.data_loader.get_texts("train")
        self.train_embeddings = self.embedding_model.encode(train_texts, show_progress_bar=True)
        self.train_labels = self.data_loader.get_labels("train")
        
        # ç”Ÿæˆæµ‹è¯•é›†åµŒå…¥
        test_texts = self.data_loader.get_texts("test")
        self.test_embeddings = self.embedding_model.encode(test_texts, show_progress_bar=True)
        self.test_labels = self.data_loader.get_labels("test")
        
        # ç¼“å­˜åµŒå…¥å‘é‡
        if cache_embeddings:
            cache_dir = Path(self.config.get('cache_dir', './cache'))
            cache_dir.mkdir(parents=True, exist_ok=True)
            
            self.embedding_model.save_embeddings(
                self.train_embeddings, 
                cache_dir / 'train_embeddings.npy'
            )
            self.embedding_model.save_embeddings(
                self.test_embeddings,
                cache_dir / 'test_embeddings.npy'
            )
        
        self.is_embeddings_generated = True
        
        embedding_info = {
            'train_embeddings_shape': self.train_embeddings.shape,
            'test_embeddings_shape': self.test_embeddings.shape,
            'embedding_dimension': self.embedding_model.get_embedding_dimension()
        }
        
        print(f"âœ… åµŒå…¥ç”Ÿæˆå®Œæˆ: {embedding_info}")
        return embedding_info
    
    def train_classifier(self, **kwargs) -> Dict[str, Any]:
        """
        è®­ç»ƒåˆ†ç±»å™¨
        
        Args:
            **kwargs: è®­ç»ƒå‚æ•°
            
        Returns:
            è®­ç»ƒç»“æœ
        """
        if not self.is_embeddings_generated:
            self.generate_embeddings()
        
        print("ğŸ¯ æ­£åœ¨è®­ç»ƒåˆ†ç±»å™¨...")
        
        # ç¼–ç æ ‡ç­¾
        encoded_labels = self.classifier.fit_transform_labels(self.train_labels)
        
        # è®­ç»ƒåˆ†ç±»å™¨
        self.classifier.train(self.train_embeddings, encoded_labels, **kwargs)
        
        self.is_model_trained = True
        
        training_info = {
            'classifier_type': self.classifier.__class__.__name__,
            'training_samples': len(self.train_embeddings),
            'num_classes': len(self.classifier.class_names) if self.classifier.class_names else None
        }
        
        print(f"âœ… åˆ†ç±»å™¨è®­ç»ƒå®Œæˆ: {training_info}")
        return training_info
    
    def predict(self, return_probabilities: bool = False) -> Dict[str, Any]:
        """
        è¿›è¡Œé¢„æµ‹
        
        Args:
            return_probabilities: æ˜¯å¦è¿”å›é¢„æµ‹æ¦‚ç‡
            
        Returns:
            é¢„æµ‹ç»“æœ
        """
        if not self.is_model_trained:
            self.train_classifier()
        
        print("ğŸ”® æ­£åœ¨è¿›è¡Œé¢„æµ‹...")
        
        # é¢„æµ‹
        predictions = self.classifier.predict(self.test_embeddings)
        
        # é¢„æµ‹æ¦‚ç‡
        probabilities = None
        if return_probabilities:
            probabilities = self.classifier.predict_proba(self.test_embeddings)
        
        # è½¬æ¢æ ‡ç­¾
        predicted_labels = self.classifier.inverse_transform_labels(predictions)
        
        self.predictions = {
            'predictions': predictions,
            'predicted_labels': predicted_labels,
            'probabilities': probabilities,
            'true_labels': self.test_labels
        }
        
        print("âœ… é¢„æµ‹å®Œæˆ")
        return self.predictions
    
    def evaluate(self) -> Dict[str, Any]:
        """
        è¯„ä¼°æ¨¡å‹æ€§èƒ½
        
        Returns:
            è¯„ä¼°ç»“æœ
        """
        if 'predictions' not in self.predictions:
            self.predict(return_probabilities=True)
        
        print("ğŸ“Š æ­£åœ¨è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
        
        # ç¼–ç çœŸå®æ ‡ç­¾ç”¨äºè¯„ä¼°
        true_labels_encoded = self.classifier.fit_transform_labels(self.test_labels)
        
        # è¯„ä¼°
        evaluation_results = self.evaluator.evaluate(
            y_true=true_labels_encoded,
            y_pred=self.predictions['predictions'],
            y_proba=self.predictions['probabilities'],
            class_names=self.class_names
        )
        
        self.results['evaluation'] = evaluation_results
        
        print("âœ… è¯„ä¼°å®Œæˆ")
        return evaluation_results
    
    def run(self, save_results: bool = True) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„æµæ°´çº¿
        
        Args:
            save_results: æ˜¯å¦ä¿å­˜ç»“æœ
            
        Returns:
            å®Œæ•´çš„è¿è¡Œç»“æœ
        """
        print("ğŸš€ å¼€å§‹è¿è¡Œæ–‡æœ¬åˆ†ç±»æµæ°´çº¿")
        print("=" * 60)
        
        start_time = datetime.now()
        
        try:
            # 1. åŠ è½½æ•°æ®
            data_info = self.load_data()
            
            # 2. ç”ŸæˆåµŒå…¥
            embedding_info = self.generate_embeddings()
            
            # 3. è®­ç»ƒåˆ†ç±»å™¨
            training_info = self.train_classifier()
            
            # 4. é¢„æµ‹
            predictions = self.predict(return_probabilities=True)
            
            # 5. è¯„ä¼°
            evaluation_results = self.evaluate()
            
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            # æ±‡æ€»ç»“æœ
            pipeline_results = {
                'config': self.config,
                'data_info': data_info,
                'embedding_info': embedding_info,
                'training_info': training_info,
                'predictions': predictions,
                'evaluation': evaluation_results,
                'pipeline_info': {
                    'start_time': start_time.isoformat(),
                    'end_time': end_time.isoformat(),
                    'duration_seconds': duration
                }
            }
            
            self.results.update(pipeline_results)
            
            # ä¿å­˜ç»“æœ
            if save_results:
                self.save_results()
            
            print(f"\nğŸ‰ æµæ°´çº¿è¿è¡Œå®Œæˆ! æ€»è€—æ—¶: {duration:.2f}ç§’")
            
            return pipeline_results
            
        except Exception as e:
            print(f"âŒ æµæ°´çº¿è¿è¡Œå¤±è´¥: {e}")
            raise
    
    def save_results(self, output_dir: Optional[str] = None) -> str:
        """
        ä¿å­˜è¿è¡Œç»“æœ
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            ä¿å­˜è·¯å¾„
        """
        if output_dir is None:
            output_dir = self.config.get('output_dir', './results')
        
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = output_path / f"classification_results_{timestamp}.json"
        
        # ä¿å­˜ç»“æœ
        with open(results_file, 'w', encoding='utf-8') as f:
            # å¤„ç†numpyæ•°ç»„ç­‰ä¸èƒ½ç›´æ¥åºåˆ—åŒ–çš„å¯¹è±¡
            serializable_results = self._make_serializable(self.results)
            json.dump(serializable_results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {results_file}")
        return str(results_file)
    
    def _make_serializable(self, obj):
        """å°†ç»“æœè½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼"""
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, dict):
            return {k: self._make_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._make_serializable(item) for item in obj]
        elif isinstance(obj, (np.int64, np.int32)):
            return int(obj)
        elif isinstance(obj, (np.float64, np.float32)):
            return float(obj)
        else:
            return obj
    
    def get_summary(self) -> str:
        """
        è·å–æµæ°´çº¿è¿è¡Œæ‘˜è¦
        
        Returns:
            æ ¼å¼åŒ–çš„æ‘˜è¦å­—ç¬¦ä¸²
        """
        if 'evaluation' not in self.results:
            return "æµæ°´çº¿å°šæœªè¿è¡Œå®Œæˆ"
        
        return self.evaluator.generate_summary(self.results['evaluation']) 