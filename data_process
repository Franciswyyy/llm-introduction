# ç¡®ä¿ä½ å·²ç»å®‰è£…äº†datasetsåº“: pip install datasets
import sys

# å¯¼å…¥æˆ‘ä»¬çš„æ•°æ®é›†ç®¡ç†æ¨¡å—
try:
    from utils import get_dataset
    print("âœ… æˆåŠŸå¯¼å…¥æ•°æ®é›†ç®¡ç†æ¨¡å—")
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    print("ğŸ’¡ è¯·ç¡®ä¿utilsåŒ…å®‰è£…æ­£ç¡®")
    sys.exit(1)

# 1. ä½¿ç”¨æ™ºèƒ½æ•°æ®é›†åŠ è½½å™¨ï¼ˆæ”¯æŒæœ¬åœ°ç¼“å­˜ï¼‰
print("ğŸš€ å¯åŠ¨æ•°æ®é›†åŠ è½½å™¨...")
dataset = get_dataset()

if dataset is None:
    print("âŒ æ•°æ®é›†åŠ è½½å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
    sys.exit(1)

# 2. æŸ¥çœ‹æ•°æ®é›†çš„æ•´ä½“ç»“æ„
# ä½ ä¼šçœ‹åˆ°å®ƒåŒ…å«äº† train, validation, test ä¸‰ä¸ªéƒ¨åˆ†
print("æ•°æ®é›†ç»“æ„:")
print(dataset)


# 3. æŸ¥çœ‹è®­ç»ƒé›†çš„å‰5æ¡æ•°æ®ï¼Œçœ‹çœ‹å®ƒåˆ°åº•é•¿ä»€ä¹ˆæ ·
print("\nè®­ç»ƒé›†å‰5æ¡ç¤ºä¾‹:")
# dataset['train'] å°±åƒä¸€ä¸ªåˆ—è¡¨ï¼Œä½ å¯ä»¥ç”¨ç´¢å¼•å’Œåˆ‡ç‰‡æ¥è®¿é—®
for i in range(5):
    example = dataset['train'][i]
    # 'text' æ˜¯å½±è¯„å†…å®¹ï¼Œ'label' æ˜¯æ ‡ç­¾ (0ä»£è¡¨å·®è¯„, 1ä»£è¡¨å¥½è¯„)
    print(f"  å½±è¯„ {i+1}: {example['text']}")
    print(f"  æ ‡ç­¾: {'å¥½è¯„' if example['label'] == 1 else 'å·®è¯„'}")
    print("-" * 20)


# 4. æ•°æ®æ¢ç´¢ - æŸ¥çœ‹å‰10æ¡æ•°æ®
print("\n=== æ•°æ®æ¢ç´¢ ===")

# è·å–å‰10æ¡æ•°æ®
first_10 = dataset['train'][0:10]
print("å‰10æ¡æ•°æ®:")
print(first_10)

print("\nå‰10æ¡æ–‡æœ¬å†…å®¹:")
texts = dataset['train'][0:10]['text']
for i, text in enumerate(texts):
    print(f"{i+1}. {text[:50]}...")

print("\nå‰10æ¡æ ‡ç­¾:")
labels = dataset['train'][0:10]['label']
print(labels)

# æ­£ç¡®çš„æ ‡ç­¾ç»Ÿè®¡æ–¹æ³• - ä½¿ç”¨Pythonå†…ç½®å‡½æ•°
from collections import Counter
import matplotlib.pyplot as plt

# é…ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'DejaVu Sans', 'SimHei', 'Helvetica']
plt.rcParams['axes.unicode_minus'] = False

# ç»Ÿè®¡å‰10æ¡çš„æ ‡ç­¾åˆ†å¸ƒ
label_counts = Counter(labels)
print(f"\nå‰10æ¡æ•°æ®æ ‡ç­¾åˆ†å¸ƒ:")
print(f"å·®è¯„(0): {label_counts[0]} æ¡")
print(f"å¥½è¯„(1): {label_counts[1]} æ¡")

# ç»Ÿè®¡æ•´ä¸ªè®­ç»ƒé›†çš„æ ‡ç­¾åˆ†å¸ƒ
all_labels = dataset['train']['label']
all_label_counts = Counter(all_labels)
print(f"\næ•´ä¸ªè®­ç»ƒé›†æ ‡ç­¾åˆ†å¸ƒ:")
print(f"å·®è¯„(0): {all_label_counts[0]} æ¡")
print(f"å¥½è¯„(1): {all_label_counts[1]} æ¡")

# ç»˜åˆ¶æ ‡ç­¾åˆ†å¸ƒå›¾
plt.figure(figsize=(12, 4))

# å­å›¾1ï¼šæŸ±çŠ¶å›¾
plt.subplot(1, 2, 1)
labels_names = ['å·®è¯„', 'å¥½è¯„']
counts = [all_label_counts[0], all_label_counts[1]]
plt.bar(labels_names, counts, color=['lightcoral', 'lightgreen'])
plt.title('è®­ç»ƒé›†æ ‡ç­¾åˆ†å¸ƒ - æŸ±çŠ¶å›¾')
plt.ylabel('æ•°é‡')

# å­å›¾2ï¼šé¥¼å›¾  
plt.subplot(1, 2, 2)
plt.pie(counts, labels=labels_names, autopct='%1.1f%%', colors=['lightcoral', 'lightgreen'])
plt.title('è®­ç»ƒé›†æ ‡ç­¾åˆ†å¸ƒ - é¥¼å›¾')

plt.tight_layout()
plt.savefig('data_distribution.png', dpi=300, bbox_inches='tight')
plt.show()
print("\nğŸ“Š è®­ç»ƒé›†æ ‡ç­¾åˆ†å¸ƒå›¾å·²ä¿å­˜ä¸º data_distribution.png")

# 5. åˆ†ææ‰€æœ‰æ•°æ®é›†çš„åˆ†å¸ƒæƒ…å†µ
print("\n" + "="*60)
print("ğŸ“Š TRAINã€VALIDATIONã€TEST æ•°æ®é›†å®Œæ•´åˆ†æ")
print("="*60)

# åˆ†æå‡½æ•°
def analyze_dataset(dataset_split, split_name):
    print(f"\nğŸ” {split_name} æ•°æ®é›†åˆ†æ:")
    print(f"   æ€»æ ·æœ¬æ•°: {len(dataset_split):,} æ¡")
    
    # æ ‡ç­¾ç»Ÿè®¡
    labels = dataset_split['label']
    label_counts = Counter(labels)
    
    print(f"   å·®è¯„(0): {label_counts[0]:,} æ¡ ({label_counts[0]/len(dataset_split)*100:.1f}%)")
    print(f"   å¥½è¯„(1): {label_counts[1]:,} æ¡ ({label_counts[1]/len(dataset_split)*100:.1f}%)")
    
    # æ–‡æœ¬é•¿åº¦ç»Ÿè®¡
    text_lengths = [len(text.split()) for text in dataset_split['text']]
    avg_length = sum(text_lengths) / len(text_lengths)
    min_length = min(text_lengths)
    max_length = max(text_lengths)
    
    print(f"   å¹³å‡æ–‡æœ¬é•¿åº¦: {avg_length:.1f} è¯")
    print(f"   æœ€çŸ­æ–‡æœ¬: {min_length} è¯")
    print(f"   æœ€é•¿æ–‡æœ¬: {max_length} è¯")
    
    # æ˜¾ç¤ºå‡ ä¸ªæ ·ä¾‹
    print(f"   ğŸ“ {split_name} æ ·ä¾‹:")
    for i in range(min(3, len(dataset_split))):
        text = dataset_split[i]['text']
        label = 'å¥½è¯„ğŸ‘' if dataset_split[i]['label'] == 1 else 'å·®è¯„ğŸ‘'
        print(f"      {i+1}. [{label}] {text[:60]}...")
    
    return label_counts, text_lengths

# åˆ†æä¸‰ä¸ªæ•°æ®é›†
train_label_counts, train_lengths = analyze_dataset(dataset['train'], "TRAIN")
val_label_counts, val_lengths = analyze_dataset(dataset['validation'], "VALIDATION") 
test_label_counts, test_lengths = analyze_dataset(dataset['test'], "TEST")

# 6. ç”Ÿæˆå¯¹æ¯”å¯è§†åŒ–
print(f"\nğŸ“Š ç”Ÿæˆä¸‰ä¸ªæ•°æ®é›†å¯¹æ¯”å›¾è¡¨...")

fig, axes = plt.subplots(2, 3, figsize=(15, 10))

# ç¬¬ä¸€è¡Œï¼šæ ‡ç­¾åˆ†å¸ƒæŸ±çŠ¶å›¾
datasets_info = [
    ("Train", train_label_counts, len(dataset['train'])),
    ("Validation", val_label_counts, len(dataset['validation'])),
    ("Test", test_label_counts, len(dataset['test']))
]

for i, (name, counts, total) in enumerate(datasets_info):
    ax = axes[0, i]
    labels_names = ['å·®è¯„', 'å¥½è¯„']
    values = [counts[0], counts[1]]
    percentages = [v/total*100 for v in values]
    
    bars = ax.bar(labels_names, values, color=['lightcoral', 'lightgreen'])
    ax.set_title(f'{name} æ•°æ®é›†\næ ‡ç­¾åˆ†å¸ƒ')
    ax.set_ylabel('æ•°é‡')
    
    # æ·»åŠ ç™¾åˆ†æ¯”æ ‡ç­¾
    for bar, pct in zip(bars, percentages):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height + total*0.01,
                f'{pct:.1f}%', ha='center', va='bottom')

# ç¬¬äºŒè¡Œï¼šæ–‡æœ¬é•¿åº¦åˆ†å¸ƒ
length_data = [train_lengths, val_lengths, test_lengths]
titles = ['Train æ–‡æœ¬é•¿åº¦åˆ†å¸ƒ', 'Validation æ–‡æœ¬é•¿åº¦åˆ†å¸ƒ', 'Test æ–‡æœ¬é•¿åº¦åˆ†å¸ƒ']

for i, (lengths, title) in enumerate(zip(length_data, titles)):
    ax = axes[1, i]
    ax.hist(lengths, bins=30, alpha=0.7, color='skyblue', edgecolor='black')
    ax.set_title(title)
    ax.set_xlabel('æ–‡æœ¬é•¿åº¦ (è¯æ•°)')
    ax.set_ylabel('é¢‘æ¬¡')
    ax.axvline(sum(lengths)/len(lengths), color='red', linestyle='--', 
               label=f'å¹³å‡: {sum(lengths)/len(lengths):.1f}')
    ax.legend()

plt.tight_layout()
plt.savefig('all_datasets_analysis.png', dpi=300, bbox_inches='tight')
plt.show()
print("\nğŸ“Š å®Œæ•´æ•°æ®é›†åˆ†æå›¾å·²ä¿å­˜ä¸º all_datasets_analysis.png")

# 7. ç”Ÿæˆæ±‡æ€»å¯¹æ¯”è¡¨
print(f"\nğŸ“‹ æ•°æ®é›†æ±‡æ€»å¯¹æ¯”è¡¨:")
print("-" * 80)
print(f"{'æ•°æ®é›†':<12} {'æ€»æ•°':<8} {'å·®è¯„':<8} {'å¥½è¯„':<8} {'å·®è¯„%':<8} {'å¥½è¯„%':<8} {'å¹³å‡é•¿åº¦':<10}")
print("-" * 80)

for name, counts, lengths in [("Train", train_label_counts, train_lengths),
                              ("Validation", val_label_counts, val_lengths), 
                              ("Test", test_label_counts, test_lengths)]:
    total = counts[0] + counts[1]
    avg_len = sum(lengths) / len(lengths)
    print(f"{name:<12} {total:<8} {counts[0]:<8} {counts[1]:<8} "
          f"{counts[0]/total*100:<7.1f}% {counts[1]/total*100:<7.1f}% {avg_len:<10.1f}")

print("-" * 80)

# 8. æ•°æ®è´¨é‡æ£€æŸ¥
print(f"\nğŸ” æ•°æ®è´¨é‡æ£€æŸ¥:")
all_datasets = [dataset['train'], dataset['validation'], dataset['test']]
dataset_names = ['Train', 'Validation', 'Test']

for ds, name in zip(all_datasets, dataset_names):
    # æ£€æŸ¥ç©ºæ–‡æœ¬
    empty_texts = sum(1 for text in ds['text'] if not text.strip())
    # æ£€æŸ¥å¼‚å¸¸é•¿åº¦
    very_short = sum(1 for text in ds['text'] if len(text.strip()) < 5)
    very_long = sum(1 for text in ds['text'] if len(text.split()) > 100)
    
    print(f"   {name}:")
    print(f"     ç©ºæ–‡æœ¬: {empty_texts} æ¡")
    print(f"     è¿‡çŸ­æ–‡æœ¬(<5å­—ç¬¦): {very_short} æ¡") 
    print(f"     è¿‡é•¿æ–‡æœ¬(>100è¯): {very_long} æ¡")