#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¢„è®­ç»ƒæ¨¡å‹è¯„ä¼°è„šæœ¬
ç›´æ¥ä½¿ç”¨ twitter-roberta-base-sentiment-latest åœ¨ Rotten Tomatoes æ•°æ®é›†ä¸Šè¯„ä¼°æ€§èƒ½
æ— éœ€è®­ç»ƒï¼Œå¿«é€ŸéªŒè¯æ¨¡å‹æ•ˆæœ - åŸºäº Google Colab ä»£ç ä¼˜åŒ–
"""

import os
import numpy as np
from pathlib import Path
from tqdm import tqdm
from datasets import load_dataset
from transformers import pipeline
from transformers.pipelines.pt_utils import KeyDataset
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import torch
import warnings
warnings.filterwarnings('ignore')

# é¡¹ç›®è·¯å¾„é…ç½®
PROJECT_ROOT = Path(__file__).parent
DATASETS_DIR = PROJECT_ROOT / "datasets"

def get_device():
    """è·å–æœ€ä½³è®¾å¤‡"""
    if torch.backends.mps.is_available():
        return "mps"
    elif torch.cuda.is_available():
        return "cuda:0"
    else:
        return "cpu"

def download_dataset():
    """ä¸‹è½½æ•°æ®é›†åˆ°æœ¬åœ°"""
    print("ğŸ“¥ ä¸‹è½½ Rotten Tomatoes æ•°æ®é›†...")
    
    # è®¾ç½®æœ¬åœ°ç¼“å­˜
    os.environ['HF_DATASETS_CACHE'] = str(DATASETS_DIR)
    DATASETS_DIR.mkdir(exist_ok=True, parents=True)
    
    try:
        dataset = load_dataset("rotten_tomatoes", cache_dir=str(DATASETS_DIR))
        print(f"âœ… æ•°æ®é›†ä¿¡æ¯:")
        print(f"   è®­ç»ƒé›†: {len(dataset['train']):,} æ¡")
        print(f"   éªŒè¯é›†: {len(dataset['validation']):,} æ¡")
        print(f"   æµ‹è¯•é›†: {len(dataset['test']):,} æ¡")
        return dataset
    except Exception as e:
        print(f"âŒ æ•°æ®é›†ä¸‹è½½å¤±è´¥: {e}")
        return None

def create_pipeline():
    """åˆ›å»ºæ¨ç†pipeline"""
    model_path = "cardiffnlp/twitter-roberta-base-sentiment-latest"
    device = get_device()
    
    print(f"ğŸ”§ åˆ›å»ºæ¨ç†Pipeline:")
    print(f"   æ¨¡å‹: {model_path}")
    print(f"   è®¾å¤‡: {device}")
    
    try:
        pipe = pipeline(
            "sentiment-analysis",
            model=model_path,
            tokenizer=model_path,
            return_all_scores=True,
            device=device
        )
        print("âœ… Pipelineåˆ›å»ºæˆåŠŸ")
        return pipe
    except Exception as e:
        print(f"âŒ Pipelineåˆ›å»ºå¤±è´¥: {e}")
        return None

def run_inference(pipe, dataset):
    """è¿è¡Œæ¨ç† - åŸºäºä½ çš„Colabä»£ç """
    print("\nğŸš€ å¼€å§‹æ¨ç†...")
    
    # è·å–çœŸå®æ ‡ç­¾
    y_true = dataset["test"]["label"]
    
    # æ‰¹é‡æ¨ç†
    y_pred = []
    print("æ¨ç†è¿›åº¦:")
    
    for output in tqdm(pipe(KeyDataset(dataset["test"], "text")), total=len(dataset["test"])):
        # è·å–è´Ÿé¢å’Œæ­£é¢åˆ†æ•°
        negative_score = output[0]["score"]  # LABEL_0 (è´Ÿé¢)
        positive_score = output[2]["score"]  # LABEL_2 (æ­£é¢)
        
        # äºŒåˆ†ç±»ï¼šé€‰æ‹©åˆ†æ•°æ›´é«˜çš„ç±»åˆ«
        assignment = np.argmax([negative_score, positive_score])
        y_pred.append(assignment)
    
    print("âœ… æ¨ç†å®Œæˆ")
    return y_true, y_pred

def evaluate_performance(y_true, y_pred):
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½ - åŸºäºä½ çš„ä»£ç ä½†å¢å¼ºäº†åŠŸèƒ½"""
    print("\nğŸ“Š æ¨¡å‹æ€§èƒ½è¯„ä¼°:")
    print("=" * 50)
    
    # è®¡ç®—å‡†ç¡®ç‡
    accuracy = accuracy_score(y_true, y_pred)
    print(f"ğŸ¯ æ•´ä½“å‡†ç¡®ç‡: {accuracy:.4f}")
    
    # è¯¦ç»†åˆ†ç±»æŠ¥å‘Š
    print(f"\nğŸ“ˆ è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:")
    performance = classification_report(
        y_true, y_pred,
        target_names=["å·®è¯„ ğŸ‘", "å¥½è¯„ ğŸ‘"],
        digits=4
    )
    print(performance)
    
    return accuracy

def plot_confusion_matrix(y_true, y_pred):
    """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
    print("\nğŸ“Š ç”Ÿæˆæ··æ·†çŸ©é˜µ...")
    
    cm = confusion_matrix(y_true, y_pred)
    
    # é…ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'DejaVu Sans', 'SimHei', 'Helvetica']
    plt.rcParams['axes.unicode_minus'] = False
    
    # è®¾ç½®æ›´å¤§çš„å›¾å½¢å’Œå­—ä½“
    plt.rcParams.update({'font.size': 14})
    plt.figure(figsize=(10, 8))
    
    # åˆ›å»ºçƒ­åŠ›å›¾ï¼Œä½¿ç”¨æ›´å¤§çš„å­—ä½“
    ax = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                     xticklabels=['å·®è¯„ ğŸ‘', 'å¥½è¯„ ğŸ‘'], 
                     yticklabels=['å·®è¯„ ğŸ‘', 'å¥½è¯„ ğŸ‘'],
                     cbar_kws={'shrink': 0.8},
                     annot_kws={'size': 16})
    
    # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾ï¼Œä½¿ç”¨æ›´å¤§çš„å­—ä½“
    plt.title('é¢„è®­ç»ƒæ¨¡å‹æ··æ·†çŸ©é˜µ - Rotten Tomatoes', fontsize=18, fontweight='bold', pad=20)
    plt.xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=16, labelpad=10)
    plt.ylabel('çœŸå®æ ‡ç­¾', fontsize=16, labelpad=10)
    
    # è°ƒæ•´åˆ»åº¦æ ‡ç­¾å¤§å°
    ax.tick_params(axis='both', which='major', labelsize=14)
    
    # ç¡®ä¿å¸ƒå±€åˆé€‚
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡ï¼Œæé«˜è´¨é‡
    save_path = PROJECT_ROOT / 'pretrained_confusion_matrix.png'
    plt.savefig(save_path, dpi=400, bbox_inches='tight', facecolor='white', edgecolor='none')
    plt.show()
    print(f"ğŸ“Š æ··æ·†çŸ©é˜µå·²ä¿å­˜: {save_path}")

def sample_predictions(pipe, dataset, num_samples=5):
    """æ˜¾ç¤ºä¸€äº›é¢„æµ‹æ ·ä¾‹"""
    print(f"\nğŸ“ é¢„æµ‹æ ·ä¾‹ (éšæœº{num_samples}æ¡):")
    print("-" * 60)
    
    # éšæœºé€‰æ‹©ä¸€äº›æ ·ä¾‹
    import random
    test_data = dataset["test"]
    indices = random.sample(range(len(test_data)), num_samples)
    
    for i, idx in enumerate(indices, 1):
        text = test_data[idx]["text"]
        true_label = "å¥½è¯„ ğŸ‘" if test_data[idx]["label"] == 1 else "å·®è¯„ ğŸ‘"
        
        # é¢„æµ‹
        result = pipe(text)[0]  # å–ç¬¬ä¸€ä¸ªç»“æœ
        
        # è§£æé¢„æµ‹ç»“æœ
        negative_score = result[0]["score"]
        positive_score = result[2]["score"]
        pred_label = "å¥½è¯„ ğŸ‘" if positive_score > negative_score else "å·®è¯„ ğŸ‘"
        confidence = max(negative_score, positive_score)
        
        print(f"{i}. è¯„è®º: {text[:80]}...")
        print(f"   çœŸå®: {true_label} | é¢„æµ‹: {pred_label} | ç½®ä¿¡åº¦: {confidence:.3f}")
        print()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¬ é¢„è®­ç»ƒæ¨¡å‹å¿«é€Ÿè¯„ä¼°")
    print("ğŸš€ åŸºäº twitter-roberta-base-sentiment-latest")
    print("=" * 60)
    
    # 1. ä¸‹è½½æ•°æ®é›†
    dataset = download_dataset()
    if dataset is None:
        return
    
    # 2. åˆ›å»ºpipeline
    pipe = create_pipeline()
    if pipe is None:
        return
    
    # 3. æ˜¾ç¤ºé¢„æµ‹æ ·ä¾‹
    sample_predictions(pipe, dataset)
    
    # 4. æ‰¹é‡æ¨ç†
    y_true, y_pred = run_inference(pipe, dataset)
    
    # 5. è¯„ä¼°æ€§èƒ½
    accuracy = evaluate_performance(y_true, y_pred)
    
    # 6. ç”Ÿæˆæ··æ·†çŸ©é˜µ
    plot_confusion_matrix(y_true, y_pred)
    
    print("\n" + "=" * 60)
    print("ğŸ‰ è¯„ä¼°å®Œæˆï¼")
    print(f"ğŸ“ˆ é¢„è®­ç»ƒæ¨¡å‹åœ¨Rotten Tomatoesæµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡: {accuracy:.1%}")
    print("ğŸ’¡ å¦‚éœ€æ›´å¥½çš„æ€§èƒ½ï¼Œå¯ä»¥è¿è¡Œ python train_model.py è¿›è¡Œå¾®è°ƒ")

if __name__ == "__main__":
    main() 