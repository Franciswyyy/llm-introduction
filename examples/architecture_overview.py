#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Architecture Overview - æ–°æ¶æ„æ¦‚è§ˆ
å±•ç¤ºé‡æ„åçš„æ¨¡å—åŒ–è®¾è®¡ï¼Œä¸è¿è¡Œå…·ä½“ä»»åŠ¡
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.append(str(PROJECT_ROOT))


def show_architecture_overview():
    """å±•ç¤ºæ–°æ¶æ„æ¦‚è§ˆ"""
    print("ğŸ—ï¸ LLM Introduction é¡¹ç›® - æ–°æ¶æ„æ¦‚è§ˆ")
    print("=" * 60)
    print()
    
    print("ğŸ“ é¡¹ç›®é‡æ„åçš„ç›®å½•ç»“æ„:")
    print("""
llm-introduction/
â”œâ”€â”€ core/                           # ğŸ”§ æ ¸å¿ƒåŠŸèƒ½æ¨¡å—
â”‚   â”œâ”€â”€ data/                       # ğŸ“Š æ•°æ®ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ base.py                 # åŸºç±»æ¥å£
â”‚   â”‚   â”œâ”€â”€ loaders.py              # å¤šç§æ•°æ®åŠ è½½å™¨
â”‚   â”‚   â””â”€â”€ preprocessors.py        # æ•°æ®é¢„å¤„ç†å™¨
â”‚   â”œâ”€â”€ embeddings/                 # ğŸ¤– åµŒå…¥æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ base.py                 # åŸºç±»æ¥å£
â”‚   â”‚   â”œâ”€â”€ sentence_transformer.py # STå®ç°
â”‚   â”‚   â””â”€â”€ factory.py              # æ¨¡å‹å·¥å‚
â”‚   â”œâ”€â”€ classifiers/                # ğŸ¯ åˆ†ç±»å™¨
â”‚   â”‚   â”œâ”€â”€ base.py                 # åŸºç±»æ¥å£
â”‚   â”‚   â”œâ”€â”€ supervised.py           # ç›‘ç£å­¦ä¹ 
â”‚   â”‚   â”œâ”€â”€ similarity.py           # ç›¸ä¼¼åº¦åˆ†ç±»
â”‚   â”‚   â””â”€â”€ factory.py              # åˆ†ç±»å™¨å·¥å‚
â”‚   â”œâ”€â”€ evaluation/                 # ğŸ“ˆ è¯„ä¼°æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ metrics.py              # è¯„ä¼°æŒ‡æ ‡
â”‚   â”‚   â””â”€â”€ visualizer.py           # ç»“æœå¯è§†åŒ–
â”‚   â””â”€â”€ pipeline/                   # ğŸ”„ æµæ°´çº¿
â”‚       â””â”€â”€ text_classification.py  # æ–‡æœ¬åˆ†ç±»æµæ°´çº¿
â”œâ”€â”€ tasks/                          # ğŸ¯ å…·ä½“ä¸šåŠ¡ä»»åŠ¡
â”‚   â””â”€â”€ sentiment_analysis/         # æƒ…æ„Ÿåˆ†æä»»åŠ¡
â”œâ”€â”€ examples/                       # ğŸ› ï¸ ç¤ºä¾‹å’Œå­¦ä¹ ææ–™
â”‚   â”œâ”€â”€ architecture_overview.py    # æ¶æ„æ¦‚è§ˆ
â”‚   â”œâ”€â”€ demo_new_architecture.py    # æ¼”ç¤ºè„šæœ¬
â”‚   â”œâ”€â”€ learn_datasets.py          # Datasetsåº“å­¦ä¹ 
â”‚   â””â”€â”€ learn_transformers.py      # Transformersåº“å­¦ä¹ 
â”œâ”€â”€ utils/                          # ğŸ”§ å·¥å…·å’Œé…ç½®
â”‚   â”œâ”€â”€ sentiment_analysis.yaml     # ä»»åŠ¡é…ç½®
â”‚   â””â”€â”€ data_builder.py            # æ•°æ®æ„å»ºå·¥å…·
â””â”€â”€ resources/                      # ğŸ“¦ èµ„æºæ–‡ä»¶å¤¹
    â”œâ”€â”€ datasets/                   # æ•°æ®é›†
    â”œâ”€â”€ pretrained_models/          # é¢„è®­ç»ƒæ¨¡å‹
    â””â”€â”€ trained_models/             # è®­ç»ƒåæ¨¡å‹
    """)
    
    print("\nğŸŒŸ æ–°æ¶æ„çš„æ ¸å¿ƒä¼˜åŠ¿:")
    print("  âœ… æ¨¡å—åŒ–è®¾è®¡ - æ¯ä¸ªåŠŸèƒ½éƒ½æœ‰ç‹¬ç«‹æ¨¡å—ï¼ŒèŒè´£æ¸…æ™°")
    print("  âœ… æ¥å£ç»Ÿä¸€ - æ‰€æœ‰ç»„ä»¶éµå¾ªç»Ÿä¸€çš„åŸºç±»æ¥å£")
    print("  âœ… å¯æ‰©å±•æ€§ - è½»æ¾æ·»åŠ æ–°çš„æ•°æ®æºã€æ¨¡å‹ã€åˆ†ç±»å™¨")
    print("  âœ… é…ç½®é©±åŠ¨ - é€šè¿‡YAMLæ–‡ä»¶æ§åˆ¶è¡Œä¸ºï¼Œæ— éœ€ä¿®æ”¹ä»£ç ")
    print("  âœ… å·¥å‚æ¨¡å¼ - åŠ¨æ€åˆ›å»ºä¸åŒç±»å‹çš„ç»„ä»¶")
    print("  âœ… æµæ°´çº¿åŒ– - è‡ªåŠ¨åŒ–çš„ç«¯åˆ°ç«¯å¤„ç†æµç¨‹")
    print("  âœ… å‘åå…¼å®¹ - ä¿ç•™åŸæœ‰utilsæ¨¡å—")
    
    print("\nğŸ”§ ç»„ä»¶ç¤ºä¾‹:")
    demonstrate_components()
    
    print("\nğŸ“‹ ä½¿ç”¨ç¤ºä¾‹:")
    show_usage_examples()
    
    print("\nğŸš€ æ‰©å±•è·¯å¾„:")
    show_extension_paths()


def demonstrate_components():
    """æ¼”ç¤ºå„ä¸ªç»„ä»¶çš„ä½¿ç”¨"""
    print("\n1. ğŸ“Š æ•°æ®åŠ è½½å™¨ - æ”¯æŒå¤šç§æ•°æ®æº")
    print("   â€¢ HuggingFaceLoader - Hugging Faceæ•°æ®é›†")
    print("   â€¢ CSVLoader - CSVæ–‡ä»¶")
    print("   â€¢ JSONLoader - JSONæ–‡ä»¶") 
    print("   â€¢ å¯è½»æ¾æ·»åŠ æ–°çš„æ•°æ®æº...")
    
    print("\n2. ğŸ¤– åµŒå…¥æ¨¡å‹ - æ”¯æŒå¤šç§åµŒå…¥æ–¹æ³•")
    print("   â€¢ SentenceTransformerEmbedding - Sentence Transformers")
    print("   â€¢ å¯æ‰©å±•ï¼šOpenAI Embedding, Hugging Face Embedding...")
    
    print("\n3. ğŸ¯ åˆ†ç±»å™¨ - æ”¯æŒå¤šç§ç®—æ³•")
    print("   â€¢ LogisticRegressionClassifier - é€»è¾‘å›å½’")
    print("   â€¢ SVMClassifier - æ”¯æŒå‘é‡æœº")
    print("   â€¢ RandomForestClassifier - éšæœºæ£®æ—")
    print("   â€¢ SimilarityClassifier - ç›¸ä¼¼åº¦åˆ†ç±»")
    print("   â€¢ å¯æ‰©å±•ï¼šæ·±åº¦å­¦ä¹ åˆ†ç±»å™¨ã€AutoML...")
    
    print("\n4. ğŸ“ˆ è¯„ä¼°æ¨¡å— - å…¨é¢çš„æ€§èƒ½è¯„ä¼°")
    print("   â€¢ ClassificationEvaluator - åˆ†ç±»è¯„ä¼°")
    print("   â€¢ ResultVisualizer - ç»“æœå¯è§†åŒ–")
    print("   â€¢ æ”¯æŒå¤šç§æŒ‡æ ‡å’Œå¯è§†åŒ–æ–¹å¼")


def show_usage_examples():
    """å±•ç¤ºä½¿ç”¨ç¤ºä¾‹"""
    print("\nğŸ’¡ é…ç½®é©±åŠ¨çš„ä½¿ç”¨æ–¹å¼:")
    print("""
# 1. é€šè¿‡é…ç½®æ–‡ä»¶å®šä¹‰ä»»åŠ¡
config = {
    "data": {"loader": "HuggingFaceLoader", "dataset": "rotten_tomatoes"},
    "embedding": {"model": "sentence-transformers/all-mpnet-base-v2"},
    "classifier": {"type": "LogisticRegression", "params": {"C": 1.0}}
}

# 2. è‡ªåŠ¨æ„å»ºæµæ°´çº¿å¹¶æ‰§è¡Œ
pipeline = TextClassificationPipeline.from_config(config)
results = pipeline.run()
    """)
    
    print("ğŸ”§ çµæ´»çš„ç»„ä»¶ç»„åˆ:")
    print("""
# å¯ä»¥è½»æ¾åˆ‡æ¢ä¸åŒç»„ä»¶
pipeline = TextClassificationPipeline(
    data_loader=CSVLoader("custom_data.csv"),
    embedding_model=SentenceTransformerEmbedding(config),
    classifier=RandomForestClassifier(config),
    evaluator=ClassificationEvaluator(config)
)
    """)


def show_extension_paths():
    """å±•ç¤ºæ‰©å±•è·¯å¾„"""
    print("ğŸ”® çŸ­æœŸæ‰©å±•:")
    print("  â€¢ æ·»åŠ æ›´å¤šåˆ†ç±»ç®—æ³•ï¼ˆç¥ç»ç½‘ç»œã€XGBoostç­‰ï¼‰")
    print("  â€¢ æ”¯æŒå¤šè¯­è¨€åµŒå…¥æ¨¡å‹")
    print("  â€¢ é›†æˆæ›´å¤šæ•°æ®æºï¼ˆæ•°æ®åº“ã€APIç­‰ï¼‰")
    
    print("\nğŸš€ ä¸­æœŸæ‰©å±•:")
    print("  â€¢ æ·»åŠ æ·±åº¦å­¦ä¹ åˆ†ç±»å™¨")
    print("  â€¢ æ”¯æŒå¤šæ ‡ç­¾åˆ†ç±»")
    print("  â€¢ å®ç°æ¨¡å‹å‹ç¼©å’ŒåŠ é€Ÿ")
    print("  â€¢ é›†æˆè¶…å‚æ•°è°ƒä¼˜")
    
    print("\nğŸŒŸ é•¿æœŸæ‰©å±•:")
    print("  â€¢ æ”¯æŒåœ¨çº¿å­¦ä¹ å’Œå¢é‡å­¦ä¹ ")
    print("  â€¢ é›†æˆAutoMLåŠŸèƒ½")
    print("  â€¢ æ„å»ºWeb APIæœåŠ¡")
    print("  â€¢ æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒ")


def show_migration_benefits():
    """å±•ç¤ºè¿ç§»çš„å¥½å¤„"""
    print("\nğŸ“ˆ ä¸åŸæ¶æ„å¯¹æ¯”:")
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘    æ–¹é¢      â•‘     åŸæ¶æ„         â•‘     æ–°æ¶æ„         â•‘")
    print("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
    print("â•‘  ä»£ç ç»„ç»‡    â•‘  å¹³é“ºå¼æ–‡ä»¶       â•‘  æ¨¡å—åŒ–ç›®å½•ç»“æ„   â•‘")
    print("â•‘  å¯æ‰©å±•æ€§    â•‘  éœ€ä¿®æ”¹ç°æœ‰ä»£ç    â•‘  æ’ä»¶å¼æ‰©å±•       â•‘")
    print("â•‘  é…ç½®ç®¡ç†    â•‘  ç¡¬ç¼–ç å‚æ•°       â•‘  YAMLé…ç½®æ–‡ä»¶     â•‘")
    print("â•‘  æµ‹è¯•æ”¯æŒ    â•‘  éš¾ä»¥å•å…ƒæµ‹è¯•     â•‘  æ¯ä¸ªæ¨¡å—å¯æµ‹è¯•   â•‘")
    print("â•‘  ä»£ç å¤ç”¨    â•‘  é‡å¤ä»£ç è¾ƒå¤š     â•‘  é«˜åº¦å¤ç”¨         â•‘")
    print("â•‘  ç»´æŠ¤æˆæœ¬    â•‘  è¾ƒé«˜             â•‘  è¾ƒä½             â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")


def main():
    """ä¸»å‡½æ•°"""
    show_architecture_overview()
    show_migration_benefits()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æ–°æ¶æ„é‡æ„å®Œæˆï¼")
    print("ğŸ“š è¯¦ç»†æ–‡æ¡£è¯·æŸ¥çœ‹ï¼šé¡¹ç›®é‡æ„æ–¹æ¡ˆ.md")
    print("ğŸ› ï¸ ä½¿ç”¨æŒ‡å—è¯·æŸ¥çœ‹ï¼šåµŒå…¥åˆ†ç±»ä»»åŠ¡æŒ‡å—.md")
    print("ğŸ“– å‘½ä»¤å‚è€ƒè¯·æŸ¥çœ‹ï¼šå‘½ä»¤å‚è€ƒæ‰‹å†Œ.md")
    print("=" * 60)


if __name__ == "__main__":
    main() 