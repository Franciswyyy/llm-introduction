#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”µå½±è¯„è®ºæƒ…æ„Ÿåˆ†æé¢„æµ‹è„šæœ¬
ä½¿ç”¨è®­ç»ƒå¥½çš„æœ¬åœ°æ¨¡å‹è¿›è¡Œé¢„æµ‹
"""

import torch
from pathlib import Path
from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
import warnings
warnings.filterwarnings('ignore')

# é¡¹ç›®è·¯å¾„é…ç½®
PROJECT_ROOT = Path(__file__).parent
MODELS_DIR = PROJECT_ROOT / "models"
PRETRAINED_MODEL_DIR = MODELS_DIR / "twitter-roberta-base-sentiment-latest"
TRAINED_MODEL_DIR = PROJECT_ROOT / "trained_model"

class SentimentPredictor:
    def __init__(self):
        # è®¾ç½®è®¾å¤‡
        if torch.backends.mps.is_available():
            self.device = torch.device("mps")
            print("âœ… ä½¿ç”¨ MPS åŠ é€Ÿé¢„æµ‹")
        elif torch.cuda.is_available():
            self.device = torch.device("cuda")
            print("âœ… ä½¿ç”¨ CUDA åŠ é€Ÿé¢„æµ‹")
        else:
            self.device = torch.device("cpu")
            print("âš ï¸  ä½¿ç”¨ CPU é¢„æµ‹")
        
        # é€‰æ‹©æ¨¡å‹è·¯å¾„ï¼ˆä¼˜å…ˆä½¿ç”¨è®­ç»ƒåçš„æ¨¡å‹ï¼‰
        if TRAINED_MODEL_DIR.exists() and any(TRAINED_MODEL_DIR.iterdir()):
            model_path = str(TRAINED_MODEL_DIR)
            print(f"ğŸ¯ ä½¿ç”¨è®­ç»ƒåçš„æ¨¡å‹: {model_path}")
        elif PRETRAINED_MODEL_DIR.exists() and any(PRETRAINED_MODEL_DIR.iterdir()):
            model_path = str(PRETRAINED_MODEL_DIR)
            print(f"ğŸ”§ ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹: {model_path}")
        else:
            print("âŒ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ï¼")
            print("è¯·å…ˆè¿è¡Œ python train_model.py è®­ç»ƒæ¨¡å‹")
            raise FileNotFoundError("æ¨¡å‹ä¸å­˜åœ¨")
        
        # åŠ è½½æ¨¡å‹
        print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(model_path)
            self.model = AutoModelForSequenceClassification.from_pretrained(model_path)
            self.model.to(self.device)
            self.model.eval()
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def predict(self, text):
        """é¢„æµ‹å•æ¡æ–‡æœ¬çš„æƒ…æ„Ÿ"""
        # ç¼–ç æ–‡æœ¬
        inputs = self.tokenizer(
            text, 
            return_tensors="pt", 
            truncation=True, 
            padding=True, 
            max_length=512
        ).to(self.device)
        
        # é¢„æµ‹
        with torch.no_grad():
            outputs = self.model(**inputs)
            probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)
            predicted_label = torch.argmax(probabilities, dim=-1).item()
            confidence = probabilities[0][predicted_label].item()
        
        # ç»“æœæ˜ å°„
        label_mapping = {0: "å·®è¯„ ğŸ‘", 1: "å¥½è¯„ ğŸ‘"}
        
        return {
            "text": text,
            "prediction": label_mapping[predicted_label],
            "confidence": confidence,
            "scores": {
                "å·®è¯„": probabilities[0][0].item(),
                "å¥½è¯„": probabilities[0][1].item()
            }
        }

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¬ ç”µå½±è¯„è®ºæƒ…æ„Ÿåˆ†æé¢„æµ‹å™¨")
    print("=" * 40)
    
    # åˆ›å»ºé¢„æµ‹å™¨
    try:
        predictor = SentimentPredictor()
    except:
        return
    
    # ç¤ºä¾‹é¢„æµ‹
    examples = [
        "This movie is absolutely amazing! Great acting and wonderful story.",
        "Terrible waste of time. Boring plot and bad acting.",
        "Not bad, but could be better. Average movie overall.",
        "Outstanding performance! Highly recommended!",
        "è¿™éƒ¨ç”µå½±å¤ªæ£’äº†ï¼æ¼”æŠ€ç²¾æ¹›ï¼Œå‰§æƒ…å¼•äººå…¥èƒœã€‚"
    ]
    
    print("\nğŸ“ ç¤ºä¾‹é¢„æµ‹:")
    print("-" * 40)
    
    for i, text in enumerate(examples, 1):
        result = predictor.predict(text)
        print(f"{i}. {text}")
        print(f"   é¢„æµ‹: {result['prediction']}")
        print(f"   ç½®ä¿¡åº¦: {result['confidence']:.3f}")
        print()
    
    # äº¤äº’å¼é¢„æµ‹
    print("ğŸ¯ äº¤äº’å¼é¢„æµ‹ (è¾“å…¥ 'quit' é€€å‡º):")
    print("-" * 40)
    
    while True:
        try:
            user_input = input("\nè¯·è¾“å…¥ç”µå½±è¯„è®º: ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º', 'q']:
                print("ğŸ‘‹ å†è§ï¼")
                break
            
            if not user_input:
                print("âš ï¸  è¯·è¾“å…¥æœ‰æ•ˆçš„æ–‡æœ¬")
                continue
            
            result = predictor.predict(user_input)
            
            print(f"ğŸ“Š é¢„æµ‹ç»“æœ:")
            print(f"   æƒ…æ„Ÿ: {result['prediction']}")
            print(f"   ç½®ä¿¡åº¦: {result['confidence']:.3f}")
            
            # ç½®ä¿¡åº¦æç¤º
            if result['confidence'] > 0.8:
                print("   ğŸ¯ é«˜ç½®ä¿¡åº¦")
            elif result['confidence'] > 0.6:
                print("   âš–ï¸  ä¸­ç­‰ç½®ä¿¡åº¦")
            else:
                print("   ğŸ¤” ä½ç½®ä¿¡åº¦")
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"âŒ é¢„æµ‹å‡ºé”™: {e}")

if __name__ == "__main__":
    main() 