#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”Ÿæˆæ¨¡å‹æ–‡æœ¬åˆ†ç±»ä»»åŠ¡
ä½¿ç”¨Text2Textç”Ÿæˆæ¨¡å‹(å¦‚FLAN-T5)é€šè¿‡promptå·¥ç¨‹è¿›è¡Œæƒ…æ„Ÿåˆ†æ
å°†åˆ†ç±»ä»»åŠ¡è½¬æ¢ä¸ºæ–‡æœ¬ç”Ÿæˆä»»åŠ¡ï¼Œè®©æ¨¡å‹ç”Ÿæˆ"positive"æˆ–"negative"æ ‡ç­¾
"""

import sys
import numpy as np
from pathlib import Path
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.append(str(PROJECT_ROOT))

# å¯¼å…¥å¿…è¦çš„åº“å’Œæ¨¡å—
from transformers.pipelines.pt_utils import KeyDataset
from sklearn.metrics import classification_report
from core.data.loaders import HuggingFaceLoader
from utils import load_generation_pipeline


def preprocess_data_with_prompt(data, prompt="Is the following sentence positive or negative? "):
    """
    ä¸ºæ•°æ®æ·»åŠ promptï¼Œå°†åˆ†ç±»ä»»åŠ¡è½¬æ¢ä¸ºç”Ÿæˆä»»åŠ¡
    
    Args:
        data: HuggingFaceæ•°æ®é›†
        prompt: ç”¨äºå¼•å¯¼æ¨¡å‹çš„æç¤ºæ–‡æœ¬
        
    Returns:
        å¤„ç†åçš„æ•°æ®é›†
    """
    print(f"ğŸ”§ æ·»åŠ prompt: '{prompt}'")
    
    # ä¸ºæ¯ä¸ªæ ·æœ¬æ·»åŠ prompt
    def add_prompt(example):
        return {"t5_input": prompt + example['text']}
    
    processed_data = data.map(add_prompt)
    return processed_data


def parse_generated_text(generated_text):
    """
    è§£æç”Ÿæˆçš„æ–‡æœ¬ï¼Œæå–åˆ†ç±»ç»“æœ
    
    Args:
        generated_text: æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬
        
    Returns:
        int: 0è¡¨ç¤ºè´Ÿé¢ï¼Œ1è¡¨ç¤ºæ­£é¢
    """
    text = generated_text.lower().strip()
    
    # å¤„ç†å„ç§å¯èƒ½çš„ç”Ÿæˆç»“æœ
    if "negative" in text:
        return 0
    elif "positive" in text:
        return 1
    elif "bad" in text or "poor" in text or "terrible" in text:
        return 0
    elif "good" in text or "great" in text or "excellent" in text:
        return 1
    else:
        # å¦‚æœæ— æ³•æ˜ç¡®åˆ¤æ–­ï¼Œé»˜è®¤è¿”å›æ­£é¢ï¼ˆå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´ï¼‰
        print(f"âš ï¸  æ— æ³•è§£æçš„ç”Ÿæˆæ–‡æœ¬: '{generated_text}', é»˜è®¤ä¸ºæ­£é¢")
        return 1


def evaluate_performance(y_true, y_pred):
    """
    è¯„ä¼°åˆ†ç±»æ€§èƒ½
    
    Args:
        y_true: çœŸå®æ ‡ç­¾
        y_pred: é¢„æµ‹æ ‡ç­¾
    """
    print("ğŸ“Š ç”Ÿæˆæ¨¡å‹åˆ†ç±»æ€§èƒ½è¯„ä¼°:")
    print("=" * 50)
    
    # è¯¦ç»†åˆ†ç±»æŠ¥å‘Š
    report = classification_report(
        y_true, y_pred,
        target_names=["è´Ÿé¢è¯„ä»·", "æ­£é¢è¯„ä»·"],
        digits=4
    )
    print(report)


def main():
    try:
        # 1. åŠ è½½æ•°æ®é›†
        print("ğŸ“Š åŠ è½½æ•°æ®é›†...")
        data = HuggingFaceLoader.load_dataset("rotten_tomatoes")
        
        if data is None:
            raise Exception("æ•°æ®é›†åŠ è½½å¤±è´¥")
        
        # 2. åŠ è½½æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ï¼ˆä½¿ç”¨é…ç½®åŒ–ç¼“å­˜ç³»ç»Ÿï¼‰
        print("ğŸ¤– åŠ è½½ç”Ÿæˆæ¨¡å‹...")
        # å¼ºåˆ¶ä½¿ç”¨CPUé¿å…MPSå…¼å®¹æ€§é—®é¢˜
        pipe = load_generation_pipeline("google/flan-t5-small", device="cpu")
        
        # 3. é¢„å¤„ç†æ•°æ®ï¼šæ·»åŠ prompt
        print("ğŸ”§ é¢„å¤„ç†æ•°æ®...")
        prompt = "Classify this movie review as positive or negative: "
        processed_data = preprocess_data_with_prompt(data, prompt)
        
        # 4. ç”Ÿæˆé¢„æµ‹ç»“æœ
        print("ğŸ”® æ‰§è¡Œæ–‡æœ¬ç”Ÿæˆåˆ†ç±»...")
        y_pred = []
        
        # åªä½¿ç”¨æµ‹è¯•é›†çš„ä¸€ä¸ªå­é›†è¿›è¡Œå¿«é€Ÿæµ‹è¯•ï¼ˆå¯ä»¥è°ƒæ•´å¤§å°ï¼‰
        test_size = min(100, len(processed_data["test"]))  # é™åˆ¶æµ‹è¯•æ ·æœ¬æ•°é‡ä»¥èŠ‚çœæ—¶é—´
        print(f"ğŸ“ å¤„ç† {test_size} ä¸ªæµ‹è¯•æ ·æœ¬...")
        
        # ä½¿ç”¨è¿›åº¦æ¡æ˜¾ç¤ºç”Ÿæˆè¿›åº¦ï¼Œå¹¶è®¾ç½®ç”Ÿæˆå‚æ•°
        for i, output in enumerate(tqdm(
            pipe(KeyDataset(processed_data["test"], "t5_input"),
                 max_length=5,  # é™åˆ¶ç”Ÿæˆé•¿åº¦ 
                 temperature=0.1,  # é™ä½éšæœºæ€§
                 do_sample=True,  # å¯ç”¨é‡‡æ ·
                 num_return_sequences=1), 
            total=test_size,
            desc="ç”Ÿæˆä¸­"
        )):
            if i >= test_size:
                break
                
            generated_text = output[0]["generated_text"]
            prediction = parse_generated_text(generated_text)
            y_pred.append(prediction)
        
        # 5. è¯„ä¼°æ€§èƒ½
        evaluate_performance(data["test"]["label"][:test_size], y_pred)
        
        # 6. æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹ç”Ÿæˆç»“æœ
        print("\nğŸ’¡ ç¤ºä¾‹ç”Ÿæˆç»“æœ:")
        print("-" * 50)
        for i in range(min(5, len(y_pred))):
            original_text = data["test"]["text"][i][:100] + "..."
            prompt_text = processed_data["test"]["t5_input"][i]
            
            # é‡æ–°ç”Ÿæˆä¸€ä¸ªç¤ºä¾‹æ¥æ˜¾ç¤º
            sample_output = pipe(prompt_text, max_length=5, temperature=0.1, do_sample=True, num_return_sequences=1)
            generated = sample_output[0]["generated_text"]
            predicted_label = "æ­£é¢" if y_pred[i] == 1 else "è´Ÿé¢"
            true_label = "æ­£é¢" if data["test"]["label"][i] == 1 else "è´Ÿé¢"
            
            print(f"ğŸ“ åŸæ–‡: {original_text}")
            print(f"ğŸ¤– ç”Ÿæˆ: {generated}")
            print(f"ğŸ¯ é¢„æµ‹: {predicted_label} | çœŸå®: {true_label}")
            print("-" * 30)
            
    except Exception as e:
        print(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 