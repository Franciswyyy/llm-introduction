# 文本分类任务性能对比分析

> 生成时间: 2025-07-20 18:35:44

## 📋 任务概述

本报告对比了三种不同的文本分类方法在Rotten Tomatoes数据集上的性能表现：

1. **预训练模型直接分类** (`01_specific_task_v2.py`)
   - 使用twitter-roberta-base-sentiment-latest预训练模型
   - 无需训练，直接进行情感分析
   
2. **嵌入模型+分类器** (`02_embedding_classific.py`)
   - 使用Sentence Transformer生成文本嵌入
   - 训练逻辑回归分类器进行分类
   
3. **零样本分类** (`03_zero_shot_classification.py`)
   - 使用预训练嵌入模型计算文本与标签的相似度
   - 无需训练数据，通过相似度进行分类

## 📊 性能对比

### 详细分类报告

#### 预训练模型直接分类

```
                 precision    recall  f1-score   support

Negative Review       0.76      0.88      0.81       533
Positive Review       0.86      0.72      0.78       533

       accuracy                           0.80      1066
      macro avg       0.81      0.80      0.80      1066
   weighted avg       0.81      0.80      0.80      1066
```

解释：

precision精准率，表示结果准不准，有没有误判。宁可放过，也不错杀。

recall 召回率，表示全不全，有多少没有被漏掉。宁可错杀，也不放过。

F1是两者的调和平均数，兼顾了两则。两者高分数也高。

support表示真实数据集中的样本数量。

accuracy准确率，macro avg宏平均，weighted avg加权平均。
这三种是看样本数量的，准确率是直观的指标，统一加起来做平均，但是如果某一类别数量很多则会有偏差； 宏平均是不考虑样本数量，平等的看待每一个类别，而加权平均则会按照权重进行统计。

Negative Review负面评价有76%，所有模型中负面评价中，有76%确实是负面评价；召回率有88%。表示所有负面评价中，只找到了其中的88%，




#### 嵌入模型+分类器

```
              precision    recall  f1-score   support

        负面评价     0.8376    0.8518    0.8447       533
        正面评价     0.8492    0.8349    0.8420       533

    accuracy                         0.8433      1066
   macro avg     0.8434    0.8433    0.8433      1066
weighted avg     0.8434    0.8433    0.8433      1066
```

#### 零样本分类

```
              precision    recall  f1-score   support

        负面评价     0.7839    0.7692    0.7765       533
        正面评价     0.7735    0.7880    0.7807       533

    accuracy                         0.7786      1066
   macro avg     0.7787    0.7786    0.7786      1066
weighted avg     0.7787    0.7786    0.7786      1066
```

### 性能指标汇总

| 方法 | 精确率 | 召回率 | F1分数 | 状态 |
|------|--------|--------|--------|------|
| 预训练模型直接分类 | 0.8100 | 0.8000 | 0.8000 | ✅ 成功 |
| 嵌入模型+分类器 | 0.8434 | 0.8433 | 0.8433 | ✅ 成功 |
| 零样本分类 | 0.7787 | 0.7786 | 0.7786 | ✅ 成功 |


## 📖 结果解释

### 性能指标说明

- **精确率 (Precision)**: 预测为正类的样本中，真正为正类的比例
  - 公式: TP / (TP + FP)
  - 值越高表示假阳性越少

- **召回率 (Recall)**: 实际为正类的样本中，被正确预测为正类的比例
  - 公式: TP / (TP + FN)
  - 值越高表示假阴性越少

- **F1分数 (F1-Score)**: 精确率和召回率的调和平均数
  - 公式: 2 × (Precision × Recall) / (Precision + Recall)
  - 综合评估指标，平衡精确率和召回率

### 方法对比分析

1. **预训练模型直接分类**
   - 优点: 实现简单，性能通常较好，无需训练
   - 缺点: 模型固定，难以针对特定任务优化

2. **嵌入模型+分类器**
   - 优点: 可以根据具体数据进行训练优化
   - 缺点: 需要训练数据，计算开销较大

3. **零样本分类**
   - 优点: 无需训练数据，灵活性高
   - 缺点: 性能可能不如专门训练的模型

### 应用建议

- 当有足够标注数据时，推荐使用**嵌入模型+分类器**方法
- 当需要快速部署且无训练数据时，推荐使用**零样本分类**
- 当追求最佳性能且适合预训练模型的任务时，推荐使用**预训练模型直接分类**

## 🔧 技术细节

- **数据集**: Rotten Tomatoes (影评情感分析)
- **评估指标**: 精确率、召回率、F1分数
- **标签类别**: 负面评价、正面评价 (二分类)
- **测试环境**: {os.name} 系统

---
*此报告由自动化脚本生成，用于对比不同文本分类方法的性能表现。*
