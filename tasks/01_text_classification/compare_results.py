#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ç»“æœå¯¹æ¯”åˆ†æè„šæœ¬
è¿è¡Œä¸‰ä¸ªä¸åŒçš„åˆ†ç±»æ–¹æ³•å¹¶ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
"""

import sys
import subprocess
import os
import re
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.append(str(PROJECT_ROOT))

def run_script_and_capture_output(script_path):
    """
    è¿è¡ŒPythonè„šæœ¬å¹¶æ•è·è¾“å‡º
    
    Args:
        script_path: Pythonè„šæœ¬è·¯å¾„
        
    Returns:
        tuple: (return_code, stdout, stderr)
    """
    try:
        print(f"ğŸš€ æ­£åœ¨è¿è¡Œ: {script_path}")
        result = subprocess.run(
            [sys.executable, script_path],
            capture_output=True,
            text=True,
            cwd=PROJECT_ROOT
        )
        return result.returncode, result.stdout, result.stderr
    except Exception as e:
        return -1, "", str(e)

def extract_classification_report(output):
    """
    ä»è¾“å‡ºä¸­æå–åˆ†ç±»æŠ¥å‘Š
    
    Args:
        output: è„šæœ¬è¾“å‡ºæ–‡æœ¬
        
    Returns:
        str: æå–çš„åˆ†ç±»æŠ¥å‘Š
    """
    lines = output.split('\n')
    report_lines = []
    in_report = False
    
    for line in lines:
        # å¯»æ‰¾åˆ†ç±»æŠ¥å‘Šçš„å¼€å§‹
        if 'precision' in line and 'recall' in line and 'f1-score' in line:
            in_report = True
            report_lines.append(line)
            continue
            
        if in_report:
            # å¦‚æœé‡åˆ°ç©ºè¡Œä¸”å·²ç»æ”¶é›†äº†è¶³å¤Ÿçš„å†…å®¹ï¼Œç»“æŸæ”¶é›†
            if line.strip() == '' and len(report_lines) > 5:
                break
            report_lines.append(line)
            
    return '\n'.join(report_lines) if report_lines else "æœªæ‰¾åˆ°åˆ†ç±»æŠ¥å‘Š"

def extract_performance_metrics(report):
    """
    ä»åˆ†ç±»æŠ¥å‘Šä¸­æå–å…³é”®æ€§èƒ½æŒ‡æ ‡
    
    Args:
        report: åˆ†ç±»æŠ¥å‘Šæ–‡æœ¬
        
    Returns:
        dict: åŒ…å«ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°çš„å­—å…¸
    """
    metrics = {}
    
    # æŸ¥æ‰¾å®å¹³å‡æˆ–åŠ æƒå¹³å‡è¡Œ
    lines = report.split('\n')
    for line in lines:
        if 'macro avg' in line or 'weighted avg' in line:
            parts = line.split()
            if len(parts) >= 4:
                try:
                    metrics['precision'] = float(parts[-4])
                    metrics['recall'] = float(parts[-3])
                    metrics['f1_score'] = float(parts[-2])
                    break
                except (ValueError, IndexError):
                    continue
                    
    return metrics

def generate_markdown_report(results):
    """
    ç”ŸæˆMarkdownæ ¼å¼çš„å¯¹æ¯”æŠ¥å‘Š
    
    Args:
        results: åŒ…å«ä¸‰ä¸ªä»»åŠ¡ç»“æœçš„å­—å…¸
    """
    report_content = f"""# æ–‡æœ¬åˆ†ç±»ä»»åŠ¡æ€§èƒ½å¯¹æ¯”åˆ†æ

> ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“‹ ä»»åŠ¡æ¦‚è¿°

æœ¬æŠ¥å‘Šå¯¹æ¯”äº†å››ç§ä¸åŒçš„æ–‡æœ¬åˆ†ç±»æ–¹æ³•åœ¨Rotten Tomatoesæ•°æ®é›†ä¸Šçš„æ€§èƒ½è¡¨ç°ï¼š

1. **é¢„è®­ç»ƒæ¨¡å‹ç›´æ¥åˆ†ç±»** (`01_specific_task_v2.py`)
   - ä½¿ç”¨twitter-roberta-base-sentiment-latesté¢„è®­ç»ƒæ¨¡å‹
   - æ— éœ€è®­ç»ƒï¼Œç›´æ¥è¿›è¡Œæƒ…æ„Ÿåˆ†æ
   
2. **åµŒå…¥æ¨¡å‹+åˆ†ç±»å™¨** (`02_embedding_classific.py`)
   - ä½¿ç”¨Sentence Transformerç”Ÿæˆæ–‡æœ¬åµŒå…¥
   - è®­ç»ƒé€»è¾‘å›å½’åˆ†ç±»å™¨è¿›è¡Œåˆ†ç±»
   
3. **é›¶æ ·æœ¬åˆ†ç±»** (`03_zero_shot_classification.py`)
   - ä½¿ç”¨é¢„è®­ç»ƒåµŒå…¥æ¨¡å‹è®¡ç®—æ–‡æœ¬ä¸æ ‡ç­¾çš„ç›¸ä¼¼åº¦
   - æ— éœ€è®­ç»ƒæ•°æ®ï¼Œé€šè¿‡ç›¸ä¼¼åº¦è¿›è¡Œåˆ†ç±»
   
4. **ç”Ÿæˆæ¨¡å‹åˆ†ç±»** (`04_text_generation_classification.py`)
   - ä½¿ç”¨FLAN-T5æ–‡æœ¬ç”Ÿæˆæ¨¡å‹è¿›è¡Œprompt-basedåˆ†ç±»
   - å°†åˆ†ç±»ä»»åŠ¡è½¬æ¢ä¸ºæ–‡æœ¬ç”Ÿæˆä»»åŠ¡

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### è¯¦ç»†åˆ†ç±»æŠ¥å‘Š

"""

    # æ·»åŠ æ¯ä¸ªä»»åŠ¡çš„è¯¦ç»†ç»“æœ
    task_names = {
        '01_specific_task_v2.py': 'é¢„è®­ç»ƒæ¨¡å‹ç›´æ¥åˆ†ç±»',
        '02_embedding_classific.py': 'åµŒå…¥æ¨¡å‹+åˆ†ç±»å™¨',
        '03_zero_shot_classification.py': 'é›¶æ ·æœ¬åˆ†ç±»',
        '04_text_generation_classification.py': 'ç”Ÿæˆæ¨¡å‹åˆ†ç±»'
    }
    
    for script, data in results.items():
        task_name = task_names.get(script, script)
        report_content += f"#### {task_name}\n\n"
        
        if data['success']:
            report_content += "```\n"
            report_content += data['report']
            report_content += "\n```\n\n"
        else:
            report_content += f"âŒ **æ‰§è¡Œå¤±è´¥**: {data['error']}\n\n"
    
    # æ·»åŠ æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”è¡¨
    report_content += "### æ€§èƒ½æŒ‡æ ‡æ±‡æ€»\n\n"
    report_content += "| æ–¹æ³• | ç²¾ç¡®ç‡ | å¬å›ç‡ | F1åˆ†æ•° | çŠ¶æ€ |\n"
    report_content += "|------|--------|--------|--------|------|\n"
    
    for script, data in results.items():
        task_name = task_names.get(script, script)
        if data['success'] and data['metrics']:
            metrics = data['metrics']
            report_content += f"| {task_name} | {metrics.get('precision', 'N/A'):.4f} | {metrics.get('recall', 'N/A'):.4f} | {metrics.get('f1_score', 'N/A'):.4f} | âœ… æˆåŠŸ |\n"
        else:
            report_content += f"| {task_name} | N/A | N/A | N/A | âŒ å¤±è´¥ |\n"
    
    # æ·»åŠ ç»“æœè§£é‡Š
    report_content += """

## ğŸ“– ç»“æœè§£é‡Š

### æ€§èƒ½æŒ‡æ ‡è¯´æ˜

- **ç²¾ç¡®ç‡ (Precision)**: é¢„æµ‹ä¸ºæ­£ç±»çš„æ ·æœ¬ä¸­ï¼ŒçœŸæ­£ä¸ºæ­£ç±»çš„æ¯”ä¾‹
  - å…¬å¼: TP / (TP + FP)
  - å€¼è¶Šé«˜è¡¨ç¤ºå‡é˜³æ€§è¶Šå°‘

- **å¬å›ç‡ (Recall)**: å®é™…ä¸ºæ­£ç±»çš„æ ·æœ¬ä¸­ï¼Œè¢«æ­£ç¡®é¢„æµ‹ä¸ºæ­£ç±»çš„æ¯”ä¾‹
  - å…¬å¼: TP / (TP + FN)
  - å€¼è¶Šé«˜è¡¨ç¤ºå‡é˜´æ€§è¶Šå°‘

- **F1åˆ†æ•° (F1-Score)**: ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡æ•°
  - å…¬å¼: 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
  - ç»¼åˆè¯„ä¼°æŒ‡æ ‡ï¼Œå¹³è¡¡ç²¾ç¡®ç‡å’Œå¬å›ç‡

### æ–¹æ³•å¯¹æ¯”åˆ†æ

1. **é¢„è®­ç»ƒæ¨¡å‹ç›´æ¥åˆ†ç±»**
   - ä¼˜ç‚¹: å®ç°ç®€å•ï¼Œæ€§èƒ½é€šå¸¸è¾ƒå¥½ï¼Œæ— éœ€è®­ç»ƒ
   - ç¼ºç‚¹: æ¨¡å‹å›ºå®šï¼Œéš¾ä»¥é’ˆå¯¹ç‰¹å®šä»»åŠ¡ä¼˜åŒ–

2. **åµŒå…¥æ¨¡å‹+åˆ†ç±»å™¨**
   - ä¼˜ç‚¹: å¯ä»¥æ ¹æ®å…·ä½“æ•°æ®è¿›è¡Œè®­ç»ƒä¼˜åŒ–
   - ç¼ºç‚¹: éœ€è¦è®­ç»ƒæ•°æ®ï¼Œè®¡ç®—å¼€é”€è¾ƒå¤§

3. **é›¶æ ·æœ¬åˆ†ç±»**
   - ä¼˜ç‚¹: æ— éœ€è®­ç»ƒæ•°æ®ï¼Œçµæ´»æ€§é«˜
   - ç¼ºç‚¹: æ€§èƒ½å¯èƒ½ä¸å¦‚ä¸“é—¨è®­ç»ƒçš„æ¨¡å‹

4. **ç”Ÿæˆæ¨¡å‹åˆ†ç±»**
   - ä¼˜ç‚¹: åˆ©ç”¨ç”Ÿæˆæ¨¡å‹çš„è¯­è¨€ç†è§£èƒ½åŠ›ï¼Œå¯å¤„ç†å¤æ‚çš„prompt
   - ç¼ºç‚¹: è®¡ç®—å¼€é”€å¤§ï¼Œç”Ÿæˆç»“æœéœ€è¦åå¤„ç†

### åº”ç”¨å»ºè®®

- å½“æœ‰è¶³å¤Ÿæ ‡æ³¨æ•°æ®æ—¶ï¼Œæ¨èä½¿ç”¨**åµŒå…¥æ¨¡å‹+åˆ†ç±»å™¨**æ–¹æ³•
- å½“éœ€è¦å¿«é€Ÿéƒ¨ç½²ä¸”æ— è®­ç»ƒæ•°æ®æ—¶ï¼Œæ¨èä½¿ç”¨**é›¶æ ·æœ¬åˆ†ç±»**
- å½“è¿½æ±‚æœ€ä½³æ€§èƒ½ä¸”é€‚åˆé¢„è®­ç»ƒæ¨¡å‹çš„ä»»åŠ¡æ—¶ï¼Œæ¨èä½¿ç”¨**é¢„è®­ç»ƒæ¨¡å‹ç›´æ¥åˆ†ç±»**
- å½“éœ€è¦å¤„ç†å¤æ‚çš„è‡ªç„¶è¯­è¨€ç†è§£ä»»åŠ¡æ—¶ï¼Œæ¨èä½¿ç”¨**ç”Ÿæˆæ¨¡å‹åˆ†ç±»**

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

- **æ•°æ®é›†**: Rotten Tomatoes (å½±è¯„æƒ…æ„Ÿåˆ†æ)
- **è¯„ä¼°æŒ‡æ ‡**: ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°
- **æ ‡ç­¾ç±»åˆ«**: è´Ÿé¢è¯„ä»·ã€æ­£é¢è¯„ä»· (äºŒåˆ†ç±»)
- **æµ‹è¯•ç¯å¢ƒ**: {os.name} ç³»ç»Ÿ

---
*æ­¤æŠ¥å‘Šç”±è‡ªåŠ¨åŒ–è„šæœ¬ç”Ÿæˆï¼Œç”¨äºå¯¹æ¯”ä¸åŒæ–‡æœ¬åˆ†ç±»æ–¹æ³•çš„æ€§èƒ½è¡¨ç°ã€‚*
"""

    # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
    report_path = Path(__file__).parent / "classification_comparison_report.md"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    print(f"ğŸ“„ å¯¹æ¯”æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
    return report_path

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å¼€å§‹æ‰§è¡Œæ–‡æœ¬åˆ†ç±»ä»»åŠ¡å¯¹æ¯”åˆ†æ...")
    
    # å®šä¹‰è¦è¿è¡Œçš„è„šæœ¬
    scripts = [
        "tasks/01_text_classification/01_specific_task_v2.py",
        "tasks/01_text_classification/02_embedding_classific.py", 
        "tasks/01_text_classification/03_zero_shot_classification.py",
        "tasks/01_text_classification/04_text_generation_classification.py"
    ]
    
    results = {}
    
    # è¿è¡Œæ¯ä¸ªè„šæœ¬å¹¶æ”¶é›†ç»“æœ
    for script in scripts:
        script_path = PROJECT_ROOT / script
        script_name = os.path.basename(script)
        
        return_code, stdout, stderr = run_script_and_capture_output(script_path)
        
        if return_code == 0:
            # æå–åˆ†ç±»æŠ¥å‘Š
            report = extract_classification_report(stdout)
            metrics = extract_performance_metrics(report)
            
            results[script_name] = {
                'success': True,
                'report': report,
                'metrics': metrics,
                'stdout': stdout,
                'stderr': stderr
            }
            print(f"âœ… {script_name} æ‰§è¡ŒæˆåŠŸ")
        else:
            results[script_name] = {
                'success': False,
                'report': "",
                'metrics': {},
                'error': stderr or "æœªçŸ¥é”™è¯¯",
                'stdout': stdout,
                'stderr': stderr
            }
            print(f"âŒ {script_name} æ‰§è¡Œå¤±è´¥: {stderr}")
    
    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    report_path = generate_markdown_report(results)
    
    print("\nğŸ‰ åˆ†æå®Œæˆ! æŸ¥çœ‹ç”Ÿæˆçš„å¯¹æ¯”æŠ¥å‘Š:")
    print(f"ğŸ“ {report_path}")

if __name__ == "__main__":
    main() 