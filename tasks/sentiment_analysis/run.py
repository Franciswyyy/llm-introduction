#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Sentiment Analysis Task Runner
æƒ…æ„Ÿåˆ†æä»»åŠ¡è¿è¡Œå™¨ - æ¼”ç¤ºæ–°æ¶æ„çš„ä½¿ç”¨
"""

import sys
from pathlib import Path
import yaml

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.append(str(PROJECT_ROOT))

from core.data.loaders import HuggingFaceLoader
from core.embeddings.sentence_transformer import SentenceTransformerEmbedding
from core.classifiers.supervised import LogisticRegressionClassifier
from core.classifiers.similarity import SimilarityClassifier
from core.evaluation.metrics import ClassificationEvaluator
from core.pipeline.text_classification import TextClassificationPipeline


def run_sentiment_analysis(config_path: str = None):
    """
    è¿è¡Œæƒ…æ„Ÿåˆ†æä»»åŠ¡
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
    """
    print("ğŸš€ å¼€å§‹è¿è¡Œæƒ…æ„Ÿåˆ†æä»»åŠ¡ (æ–°æ¶æ„)")
    print("=" * 60)
    
    # é»˜è®¤é…ç½®æ–‡ä»¶
    if config_path is None:
        config_path = PROJECT_ROOT / "utils" / "sentiment_analysis.yaml"
    
    # åŠ è½½é…ç½®
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # åˆ›å»ºç»„ä»¶
    print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–ç»„ä»¶...")
    
    # 1. æ•°æ®åŠ è½½å™¨
    data_loader = HuggingFaceLoader({
        'dataset_name': config['data']['dataset_name'],
        'cache_dir': config['data']['cache_dir']
    })
    
    # 2. åµŒå…¥æ¨¡å‹
    embedding_model = SentenceTransformerEmbedding({
        'model_name': config['embedding']['model_name'],
        'device': config['embedding']['device'],
        'normalize_embeddings': config['embedding']['normalize_embeddings']
    })
    
    # 3. è¯„ä¼°å™¨
    evaluator = ClassificationEvaluator({
        'metrics': config['evaluation']['metrics'],
        'average': config['evaluation']['average']
    })
    
    # è¿è¡Œå¤šä¸ªåˆ†ç±»å™¨
    results = {}
    
    for classifier_config in config['classifiers']:
        classifier_name = classifier_config['name']
        classifier_type = classifier_config['type']
        classifier_params = classifier_config.get('params', {})
        
        print(f"\nğŸ¯ è¿è¡Œåˆ†ç±»å™¨: {classifier_name} ({classifier_type})")
        print("-" * 40)
        
        # åˆ›å»ºåˆ†ç±»å™¨
        if classifier_type == "LogisticRegressionClassifier":
            classifier = LogisticRegressionClassifier({'params': classifier_params})
        elif classifier_type == "SimilarityClassifier":
            classifier = SimilarityClassifier(classifier_params)
        else:
            print(f"âŒ ä¸æ”¯æŒçš„åˆ†ç±»å™¨ç±»å‹: {classifier_type}")
            continue
        
        # åˆ›å»ºæµæ°´çº¿
        pipeline = TextClassificationPipeline(
            data_loader=data_loader,
            embedding_model=embedding_model,
            classifier=classifier,
            evaluator=evaluator,
            config=config['pipeline']
        )
        
        # è¿è¡Œæµæ°´çº¿
        try:
            result = pipeline.run(save_results=False)
            results[classifier_name] = result
            
            # æ˜¾ç¤ºæ‘˜è¦
            print(f"\nğŸ“Š {classifier_name} ç»“æœæ‘˜è¦:")
            print(pipeline.get_summary())
            
        except Exception as e:
            print(f"âŒ {classifier_name} è¿è¡Œå¤±è´¥: {e}")
            results[classifier_name] = {'error': str(e)}
    
    # æ¯”è¾ƒç»“æœ
    if len(results) > 1:
        print(f"\nğŸ† åˆ†ç±»å™¨æ€§èƒ½å¯¹æ¯”:")
        print("=" * 60)
        
        comparison_data = []
        for name, result in results.items():
            if 'error' not in result:
                eval_results = result['evaluation']
                comparison_data.append({
                    'classifier': name,
                    'accuracy': eval_results.get('accuracy', 0),
                    'precision': eval_results.get('precision', 0),
                    'recall': eval_results.get('recall', 0),
                    'f1': eval_results.get('f1', 0)
                })
        
        # æ˜¾ç¤ºå¯¹æ¯”è¡¨æ ¼
        if comparison_data:
            print(f"{'åˆ†ç±»å™¨':<20} {'å‡†ç¡®ç‡':<10} {'ç²¾ç¡®ç‡':<10} {'å¬å›ç‡':<10} {'F1åˆ†æ•°':<10}")
            print("-" * 70)
            for row in comparison_data:
                print(f"{row['classifier']:<20} {row['accuracy']:<10.4f} {row['precision']:<10.4f} {row['recall']:<10.4f} {row['f1']:<10.4f}")
    
    print(f"\nğŸ‰ æƒ…æ„Ÿåˆ†æä»»åŠ¡å®Œæˆï¼")
    return results


if __name__ == "__main__":
    run_sentiment_analysis() 