# 项目重构方案

## 🎯 重构目标
将当前平铺式项目结构改造为模块化、可扩展的架构，支持多种数据源、嵌入模型和分类器的组合使用。

## 📁 新项目结构

```
llm-introduction/
├── core/                           # 核心功能模块
│   ├── __init__.py
│   ├── data/                       # 数据管理模块
│   │   ├── __init__.py
│   │   ├── base.py                 # 数据基类接口
│   │   ├── loaders.py              # 各种数据加载器
│   │   └── preprocessors.py        # 数据预处理器
│   ├── embeddings/                 # 嵌入模型模块
│   │   ├── __init__.py
│   │   ├── base.py                 # 嵌入模型基类
│   │   ├── sentence_transformer.py # Sentence Transformer实现
│   │   └── factory.py              # 模型工厂
│   ├── classifiers/                # 分类器模块
│   │   ├── __init__.py
│   │   ├── base.py                 # 分类器基类
│   │   ├── supervised.py           # 监督学习分类器
│   │   ├── similarity.py           # 相似度分类器
│   │   └── factory.py              # 分类器工厂
│   ├── evaluation/                 # 评估模块
│   │   ├── __init__.py
│   │   ├── metrics.py              # 评估指标
│   │   └── visualizer.py           # 结果可视化
│   └── pipeline/                   # 流水线模块
│       ├── __init__.py
│       └── text_classification.py  # 文本分类流水线
├── tasks/                          # 具体业务任务
│   ├── __init__.py
│   ├── sentiment_analysis/         # 情感分析任务
│   │   ├── __init__.py
│   │   ├── config.py               # 任务配置
│   │   ├── dataset.py              # 数据集定义
│   │   └── run.py                  # 任务执行脚本
│   └── document_classification/    # 文档分类任务（示例扩展）
│       ├── __init__.py
│       ├── config.py
│       └── run.py
├── configs/                        # 配置文件
│   ├── default.yaml                # 默认配置
│   ├── sentiment_analysis.yaml     # 情感分析配置
│   └── models.yaml                 # 模型配置
├── scripts/                        # 工具脚本
│   ├── train.py                    # 训练脚本
│   ├── evaluate.py                 # 评估脚本
│   └── export_model.py             # 模型导出
├── tests/                          # 测试模块
│   ├── __init__.py
│   ├── test_data.py
│   ├── test_embeddings.py
│   └── test_classifiers.py
├── utils/                          # 原有工具（保持兼容）
│   ├── __init__.py
│   └── data_builder.py
└── requirements/                   # 分级依赖管理
    ├── base.txt                    # 基础依赖
    ├── dev.txt                     # 开发依赖
    └── optional.txt                # 可选依赖
```

## 🏗️ 架构设计原则

### 1. 模块化设计
- **单一职责**：每个模块负责特定功能
- **松耦合**：模块间通过接口交互
- **高内聚**：相关功能聚合在同一模块

### 2. 可扩展性
- **工厂模式**：动态创建不同类型的组件
- **策略模式**：支持多种算法实现
- **配置驱动**：通过配置文件控制行为

### 3. 接口统一
- **基类定义**：统一的接口规范
- **类型提示**：完整的类型标注
- **文档规范**：标准化的文档格式

## 🔧 核心组件设计

### 数据管理模块 (core/data/)
```python
# 支持多种数据源
class DataLoader:
    - HuggingFaceLoader     # Hugging Face数据集
    - CSVLoader             # CSV文件
    - JSONLoader            # JSON文件
    - DatabaseLoader        # 数据库
    
# 数据预处理
class DataPreprocessor:
    - TextCleaner           # 文本清洗
    - Tokenizer             # 分词
    - LabelEncoder          # 标签编码
```

### 嵌入模型模块 (core/embeddings/)
```python
# 支持多种嵌入模型
class EmbeddingModel:
    - SentenceTransformer   # 当前使用的
    - OpenAIEmbedding       # OpenAI API
    - HuggingFaceEmbedding  # 其他HF模型
    - CustomEmbedding       # 自定义模型
```

### 分类器模块 (core/classifiers/)
```python
# 支持多种分类算法
class Classifier:
    - LogisticRegression    # 逻辑回归
    - SVM                   # 支持向量机
    - RandomForest          # 随机森林
    - NeuralNetwork         # 神经网络
    - SimilarityClassifier  # 相似度分类
```

### 流水线模块 (core/pipeline/)
```python
# 组合各模块形成完整流程
class TextClassificationPipeline:
    - data_loader
    - embedding_model  
    - classifier
    - evaluator
```

## 📋 重构步骤

### 第一阶段：核心架构搭建
1. 创建新的目录结构
2. 实现基类接口
3. 迁移现有功能到新架构

### 第二阶段：组件实现
1. 实现数据管理模块
2. 实现嵌入模型模块
3. 实现分类器模块

### 第三阶段：任务迁移
1. 将现有分类任务迁移到新结构
2. 创建配置文件
3. 实现流水线

### 第四阶段：完善和测试
1. 添加测试用例
2. 完善文档
3. 性能优化

## 🚀 使用示例

### 配置驱动的任务执行
```python
# 通过配置文件定义任务
config = {
    "data": {
        "loader": "HuggingFaceLoader",
        "dataset": "rotten_tomatoes"
    },
    "embedding": {
        "model": "sentence-transformers/all-mpnet-base-v2"
    },
    "classifier": {
        "type": "LogisticRegression",
        "params": {"random_state": 42}
    }
}

# 自动构建流水线并执行
pipeline = TextClassificationPipeline.from_config(config)
results = pipeline.run()
```

### 灵活的组件组合
```python
# 可以轻松切换不同组件
pipeline = TextClassificationPipeline(
    data_loader=CSVLoader("custom_data.csv"),
    embedding_model=OpenAIEmbedding("text-embedding-ada-002"),
    classifier=RandomForestClassifier(),
    evaluator=MultiMetricEvaluator()
)
```

## 🎨 配置文件示例

### sentiment_analysis.yaml
```yaml
task:
  name: "sentiment_analysis"
  description: "电影评论情感分析"

data:
  loader: "HuggingFaceLoader"
  dataset: "rotten_tomatoes"
  cache_dir: "./datasets"
  
embedding:
  model: "sentence-transformers/all-mpnet-base-v2"
  batch_size: 32
  cache_embeddings: true
  
classifiers:
  - type: "LogisticRegression"
    params:
      random_state: 42
      max_iter: 1000
  - type: "SimilarityClassifier"
    params:
      metric: "cosine"
      
evaluation:
  metrics: ["accuracy", "precision", "recall", "f1"]
  cross_validation: 5
  save_confusion_matrix: true
  
output:
  save_predictions: true
  export_model: true
  results_dir: "./results"
```

## 🔄 迁移策略

### 保持向后兼容
- 保留原有的`utils`模块
- 提供适配器转换旧接口
- 渐进式迁移

### 数据保护
- 备份现有训练结果
- 保留模型文件
- 维护Git历史

## 📈 扩展路径

### 短期扩展
1. 添加更多分类算法
2. 支持多语言模型
3. 集成更多数据源

### 中期扩展  
1. 添加深度学习分类器
2. 支持多标签分类
3. 实现模型压缩和加速

### 长期扩展
1. 支持在线学习
2. 集成AutoML功能
3. 构建Web API服务

这个重构方案将大大提升项目的可维护性和扩展性，为后续开发奠定坚实基础。 